University of San Francisco's Natural Language Processing (NLP) course <br> Summer 2018
------

__Instructor:__ Brian Spiering [bspiering@usfca.edu](mailto:bspiering@usfca.edu)  

<img src="https://pbs.twimg.com/media/BrPvG7wCMAAk6Qh.png" alt="GO FIND IMAGE" align="middle" style="width: 350px;"/>

> The mystery lies in the use of language to express human life.  
> – Eudora Welty 

----
Course Description
----

This course covers the fundamental concepts and algorithms in Natural Language Processing (NLP). The goal is to process and understand text using statistical modeling and programming.

This course will start with basic text processing techniques (such as regular expressions) and then cover advanced techniques (text classification and topic modeling). The emphasis will be on contemporary best practices in industry, including Deep Learning and text embeddings. Along the way we will touch upon text mining, information retrieval, and computational linguistics.

This is course is a "buffet" format, a sample of many things, but you will not get "full" on any one topic. People get a PhD in each of these individual topics. __Remember__ - a little bit of knowledge and a lot of "how to" goes a long way.

Prerequisites
-----

- Working knowledge of probability (e.g., calculate conditional probability and apply Bayes Theorem)
- Basic statistics (e.g., the difference between pmf and pdf)
- One course in machine learning 
- Intermediate Python (e.g., the ability to create classes). I have found that the more Python a student knows the more NLP he/she learns during the course.

-----
NLP Course Schedule
-------

1. Welcome & NLP Overview [05/22]
2. Regular Expressions [05/24]
3. Segmenting, Tokenizing, & Stemming [05/29]
4. Language Modeling [05/31]
5. Text Embeddings: Words [06/03]  
6. Text Embeddings: Documents et al. [06/07]
7. Word Tagging: POS (part of speech) and NER (named entity recognition) [06/12]
8. Text Classification / Sentiment Analysis with Naive Bayes [06/14]
9. Text Classification with Deep Learning [06/19]
10. Information Retrieval / Search Engineering [06/21]
11. Topic Modeling with Latent Dirichlet allocation (LDA) [06/26]
12. Student's Choice [06/28]  

Topics for Student's Choice
-----

- Text Encoding
- Edit Distance
- Spelling Correction
- Chatbots
- Text classification with Logistic Regression
- Advanced Sentiment Analysis
- Topic Modeling with Non-negative matrix factorization (NMF) 
- Additional Deep Learning
- Additional Information Retrieval / Search Engineering
- Text summarization

Topics Not Included
-------

- Theory. We are only going to cover applied parts of NLP, aka tips n' tricks for getting stuff done.
- Grammar. Grammar kinda sucks but it is a very powerful method for understanding language.
- Non-English languages. I ❤️ other languages, and they are very important to understanding NLP. There is just enough not time!
- Machine Translation. Again very important and incredible breakthroughs have been made. There is not enough time to adequately cover it.
- Natural Language Understanding (NLU). Finding "meaning" in text. We'll spend most of our time focused on lower levels of processing.
- Natural Language Generation (NLG). We'll only going to briefly touch on how to programmatically create text during the Language Modeling section.
- Speech. In the last couple of years, speech-based language processing has revolutionized. For this class, we'll assume audio waves have been digitized into text.

----
Grades
----

| Item | Weight  |  
|:-------:|:------:|
| Participation | 30% | 
| Labs | 30% |
| Final Project | 40% |

The expected grade for this class is a B+. Getting an A- or above requires high level participation and a stellar final project.

### Participation
You must also show up prepared. Each person is important to the dynamic of the class, and therefore students are required to participate in class activities. Expect to be "cold called". I call on students at random not to put you on the spot but to keep you engaged in the material at all times.

Attendance is mandatory. It is the responsibility of the student to attend all classes. If you have to miss class, due to sickness or other circumstances, please notify your instructor by Slack in advance. Supporting documents (doctor’s notes) should accompany absences due to sickness.

### Labs

The labs will be hands-on activities all in Jupyter Notebooks. They will require a combination of coding and self-reflection. The coding will be implementing algorithms from scratch or using common libraries (e.g., scikit-learn, nltk, and textblob). The self-reflection will be writing to explain a concept or apply a concept to new situation. 

### Final Project

Details will be covered in a future class (mostly likely the second class session).


Course Structure
-----

This course will be partly "[flipped](https://en.wikipedia.org/wiki/Flipped_classroom)", basic lectures will be videos watched before class. In class lectures will be on complex topics and [active learning](https://en.wikipedia.org/wiki/Active_learning)-style. You'll be writing a lot of code and completing many projects. 


Quotes from Past Students
-----

> - Brian is absolutely great. He's very knowledgeable and available for students. He knows how to explain material in a coherent and structured manner. He doesn't jump around from concept to concept without a proper introduction of the context. He gave me extra material when I showed deeper interest in the subject.

> - Brian's explanatory pictures have been savior.
  
> - Labs hand down have the most impact on my learning. It's only when you start implementing the concepts yourself on your computer that you come up with the best questions.

> - In the NLP class, the labs may be a struggle sometimes, but overall I think that exploratory learning process , trial and error style, is really helpful. Even if we don't feel productive, as long as there's an epiphany at the end of the minor struggle, it's all worth it.

------

More details to follow…

If you have any questions, please open an issue.
