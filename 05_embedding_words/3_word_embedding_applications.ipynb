{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now that we have word vectors, what can we do?\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Math with words!\n",
    "\n",
    "<center><img src=\"http://rlv.zcache.com/math_is_awesome_poster-re24bd4726be24b82acc1d83fe7b4a8e4_cru_8byvr_512.jpg\" width=\"700\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Types of Word Math\n",
    "----\n",
    "\n",
    "1. Distance\n",
    "2. Arithmetic\n",
    "3. Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "1. Distance\n",
    "----\n",
    "\n",
    "<center><img src=\"http://blog.krecan.net/wp-content/family.png\" width=\"600\"/></center>\n",
    "\n",
    "The relationships between words can encoded as distance through the space.\n",
    "\n",
    "Words that are related will be closer than unrelate words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Ways to measure distance\n",
    "----\n",
    "<center><img src=\"http://i1.wp.com/dataaspirant.com/wp-content/uploads/2015/04/euclidean.png?w=600\" width=\"700\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"http://i2.wp.com/dataaspirant.com/wp-content/uploads/2015/04/manhattan.png?w=600\" width=\"700\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"http://i2.wp.com/dataaspirant.com/wp-content/uploads/2015/04/cosine.png?resize=610%2C468\" width=\"700\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "[Read more here](http://dataaspirant.com/2015/04/11/five-most-popular-similarity-measures-implementation-in-python/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Check for understanding\n",
    "-----\n",
    "\n",
    "Which distance metric should we use for word vectors and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "__Cosine similarity__ is most often used in NLP.\n",
    "\n",
    "If everything is normalized unit vectors, then the two calculations are equivalent. \n",
    "\n",
    "In general, use the cosine similarity since it removes the effect of document length.\n",
    "\n",
    "The cosine distance is equivalent to the inner product of the normalized word vectors (e.g scaling the vectors so their length becomes equal to 1.) \n",
    "\n",
    "You can very loosely interpret the inner product of word vectors to be an approximation of the pointwise mutual information (PMI) between the two words they represent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "[Source](https://github.com/facebookresearch/fastText/issues/189)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"https://upload.wikimedia.org/math/f/3/6/f369863aa2814d6e283f859986a1574d.png\" width=\"900\"/></center>\n",
    "\n",
    "Interpreting cosine value:\n",
    "\n",
    "1 : word vectors are exactly the same  \n",
    "0 : word vectors are orthogonal (mathematically unrelated)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "__Student Activity__: Write a function that implements cosine similarity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "def test_cos_sim():\n",
    "    v1 = np.array([1, 2, 3])\n",
    "    assert cos_sim(v1, v1) == 1\n",
    "    assert cos_sim(v1, v1) == (1 - cosine(v1, v1)) # Distance is the inverse of similarity\n",
    "    \n",
    "    v2 = np.array([-1, -2, -3])\n",
    "    assert cos_sim(v1, v2) == -1\n",
    "    assert cos_sim(v1, v2) == (1 - cosine(v1, v2)) # Distance is the inverse of similarity\n",
    "    \n",
    "    v3 = np.array([0, 3])\n",
    "    v4 = np.array([4, 0])\n",
    "    assert cos_sim(v3, v4) == 0\n",
    "    assert cos_sim(v3, v4) == (1 - cosine(v3, v4)) # Distance is the inverse of similarity\n",
    "    \n",
    "    v5 = np.array([3, 45, 7, 2])\n",
    "    v6 = np.array([2, 54, 13, 15])\n",
    "    assert round(cos_sim(v5, v6), 4) == round(0.97228425171235, 4)\n",
    "    assert round(cos_sim(v5, v6), 4) == (1 - round(cosine(v5, v6), 4))\n",
    "    \n",
    "    return \"tests pass üôÇ\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tests pass üôÇ\n"
     ]
    }
   ],
   "source": [
    "def cos_sim(v1, v2):\n",
    "    \"Calculate cosine similarity between vector 1 and 2\"\n",
    "    return v1.dot(v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))\n",
    "\n",
    "print(test_cos_sim())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Words closest to ‚ÄúSweden‚Äù\n",
    "----\n",
    "\n",
    "<center><img src=\"http://deeplearning4j.org/img/sweden_cosine_distance.png\" width=\"700\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"images/joke.png\" width=\"700\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Check for understanding\n",
    "-----\n",
    "\n",
    "What is a limitation of word vectors (aka grouping words by correlation)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Antonyms appear to near each other (in both the data and the vector space)!\n",
    "\n",
    "__Examples__:\n",
    "\n",
    "- and / or\n",
    "- good / bad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "2. Arithmetic: Word analogies\n",
    "---\n",
    "\n",
    "The \"Hello, world!\" of word2vec:\n",
    "> Man is to woman as king is to queen\n",
    "\n",
    "$cos(w, king) - cos(w, man) + cos(w, woman) = cos(w, queen)$\n",
    "\n",
    "<center><img src=\"http://multithreaded.stitchfix.com/assets/images/blog/vectors.gif\" width=\"500\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "[Let's play with an analogy demo](http://rare-technologies.com/word2vec-tutorial/#app)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Different paths (vectors) through the space encode different relationships.\n",
    "----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Plurals (Models Suffixes)\n",
    "-----\n",
    "<center><img src=\"images/plurals.png\" width=\"700\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Verb Tense (Models Inflections)\n",
    "-----\n",
    "\n",
    "<center><img src=\"images/verb.png\" width=\"700\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Country-Capital (Models real-world relationships)\n",
    "-----\n",
    "\n",
    "<center><img src=\"images/country.png\" width=\"700\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "How can you use word2vec to build data products?\n",
    "----\n",
    "\n",
    "<center><img src=\"https://assets.toptal.io/uploads/blog/image/827/toptal-blog-image-1423052243609.jpg\" width=\"400\"/></center>\n",
    "\n",
    "When I worked at an employment website, I built a recommendation engine for job seekers. \n",
    "\n",
    "The job seeker would have a resume and we would suggest jobs for them. \n",
    "\n",
    "My goal was given a current job title, suggest a \"better\" job. This would increase platform engagement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "What would be next logical career move from a Babysitter?\n",
    "------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "________ is to __Babysitter__ as __Senior Engineer__ is to __Engineer__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "__Nanny__ is to __Babysitter__ as __Senior Engineer__ is to __Engineer__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "3) Clustering\n",
    "----\n",
    "\n",
    "<center><img src=\"http://colah.github.io/posts/2015-01-Visualizing-Representations/img/words-pic.png\" width=\"700\"/></center>\n",
    "\n",
    "Use your favorite clustering algo! (K-means is a good start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "[Example 1](http://colah.github.io/posts/2015-01-Visualizing-Representations/)\n",
    "\n",
    "[Example 2](http://douglasduhaime.com/blog/clustering-semantic-vectors-with-python)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "How can we could we unit test our word2vec model <br> (especially if it is built on a custom corpus)?\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Word2Vec is an unsupervised learning algorithm. Thus there is no good way to objectively evaluate the result. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "There is a testing approach!\n",
    "\n",
    "One possible method is to compare analogies performance with [Google analogy test set](https://aclweb.org/aclwiki/Google_analogy_test_set_(State_of_the_art)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Summary\n",
    "---\n",
    "- After training, any vector operations can be applied to words. \n",
    "- The most common operations are: \n",
    "    - Arithmetic (add and subtract)\n",
    "    - Distance (typically using Cosine Similarity)\n",
    "    - Clustering (typically K-Means)\n",
    "- When possible test, machine learning systems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "----"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
