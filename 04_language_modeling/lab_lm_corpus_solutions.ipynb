{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset -fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    from quilt.data.BrianSpiering.shakespeare import shakespeare\n",
    "except ModuleNotFoundError:\n",
    "    import os\n",
    "    os.system('quilt install BrianSpiering/shakespeare')\n",
    "    from quilt.data.BrianSpiering.shakespeare import shakespeare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(shakespeare._data()) as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def words(text):\n",
    "    \"List all the word tokens (consecutive letters) in a text. Normalize to lowercase.\"\n",
    "    return re.findall('[a-z]+', text.lower()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the', 'sonnets', 'by', 'william', 'shakespeare']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = words(text)\n",
    "text[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(bag, n=10):\n",
    "    \"Sample a random n-word sentence from the model described by the bag of words.\"\n",
    "    return ' '.join(random.sample(bag, k=n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ready it what thersites shine have morris leave hast perhaps',\n",
       " 'cleopatra a meet i sea and well tree straight off',\n",
       " 'in been i up lord hath his it the sicinius',\n",
       " 'to world lay d to be me bonfires blood of',\n",
       " 'better a of clay d man after nurse signet with',\n",
       " 'poor leap that a several lawyer best you counterfeit and',\n",
       " 'wilt her stand deeply break by proteus act guiltiness a',\n",
       " 'married render veil france he the is th love spent',\n",
       " 'thy mire amorous would and proteus a of with all',\n",
       " 'bleeding to tooth oft did thou i might but messenger']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[sample(text) for _ in range(10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__This is unigram model. It generative data based on single token frequency.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 27595),\n",
      " ('and', 26735),\n",
      " ('i', 22538),\n",
      " ('to', 19771),\n",
      " ('of', 18132),\n",
      " ('a', 14725),\n",
      " ('you', 13826),\n",
      " ('my', 12490),\n",
      " ('that', 11535),\n",
      " ('in', 11112)]\n"
     ]
    }
   ],
   "source": [
    "counts = Counter(text)\n",
    "pprint(counts.most_common(10)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('extincture', 1),\n",
      " ('daffed', 1),\n",
      " ('plenitude', 1),\n",
      " ('cautels', 1),\n",
      " ('hurting', 1),\n",
      " ('preached', 1),\n",
      " ('unexperient', 1),\n",
      " ('hovered', 1),\n",
      " ('lovered', 1),\n",
      " ('glowed', 1)]\n"
     ]
    }
   ],
   "source": [
    "pprint(counts.most_common(len(counts))[-10:]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word                  count\n",
      "------------------------------\n",
      "there                 2,210\n",
      "are                   3,880\n",
      "common                154\n",
      "and                   26,735\n",
      "neverseen             0\n",
      "words                 421\n"
     ]
    }
   ],
   "source": [
    "print(f'{\"word\":20}  {\"count\"}')\n",
    "print('-'*30)\n",
    "for word in words('there are common and neverseen words'):\n",
    "    print(f'{word:20}  {counts[word]:,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word                  probability\n",
      "------------------------------\n",
      "there                 0.0024\n",
      "are                   0.0042\n",
      "common                0.00017\n",
      "and                   0.029\n",
      "neverseen             0.0\n",
      "words                 0.00045\n"
     ]
    }
   ],
   "source": [
    "# TODO: calculate the probability of the words\n",
    "print(f'{\"word\":20}  {\"probability\"}')\n",
    "print('-'*30)\n",
    "for word in words('there are common and neverseen words'):\n",
    "    print(f'{word:20}  {counts[word]/sum(counts.values()):.2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Turn that into a function\n",
    "def word_prob(counts: dict, word: str)-> float:\n",
    "    \"Calculate the probability of a word based on evidence from a Counter.\"\n",
    "    N = sum(counts.values())\n",
    "    return counts[word]/N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert round(word_prob(counts, \"the\"), 4)  == 0.0298\n",
    "assert round(word_prob(counts, \"king\"), 4) == 0.0033"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word                  probability\n",
      "------------------------------\n",
      "there                 0.0024\n",
      "are                   0.0042\n",
      "common                0.00017\n",
      "and                   0.029\n",
      "neverseen             0.0\n",
      "words                 0.00045\n"
     ]
    }
   ],
   "source": [
    "print(f'{\"word\":20}  {\"probability\"}')\n",
    "print('-'*30)\n",
    "for word in words('there are common and neverseen words'):\n",
    "    print(f'{word:20}  {word_prob(counts, word):.2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, what is the probability of a *sequence* of words?  Use the definition of a joint probability:\n",
    "\n",
    "$P(w_1 \\ldots w_n) = P(w_1) \\times P(w_2 \\mid w_1) \\times P(w_3 \\mid w_1 w_2) \\ldots  \\times \\ldots P(w_n \\mid w_1 \\ldots w_{n-1})$\n",
    "\n",
    "The *bag of words* model assumes that each word is drawn from the bag *independently* of the others.  This gives us the wrong approximation:\n",
    "    \n",
    "$P(w_1 \\ldots w_n) = P(w_1) \\times P(w_2) \\times P(w_3) \\ldots  \\times \\ldots P(w_n)$\n",
    "\n",
    "It is wrong but okay enough to move forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_words_in_phrase(phrase):\n",
    "    \"Probability of words, assuming each word is independent of others.\"\n",
    "    return product([word_prob(counts, word) for word in words(phrase)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word                            probability\n",
      "--------------------------------------------------\n",
      "the                             0.029791\n",
      "the the                         0.000887505\n",
      "the the the                     2.64397e-05\n",
      "the sonnets by                  7.71506e-10\n",
      "this is a neverbeforeseen word  0.0\n"
     ]
    }
   ],
   "source": [
    "phrases = ['the',\n",
    "           'the the',\n",
    "           'the the the', \n",
    "           'the sonnets by',\n",
    "           'this is a neverbeforeseen word']\n",
    "\n",
    "print(f'{\"word\":30}  {\"probability\"}')\n",
    "print('-'*50)\n",
    "for phrase in phrases:\n",
    "    print(f'{phrase:30}  {prob_words_in_phrase(phrase):.6}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Why is `the the the` so likely? What would we have to add to our model to reduce the likelihood of nonsense phrases?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"the\" is very popular and the models calculates the joint probability as the product of the indepent probability\n",
    "\n",
    "We should add bigrams frequency or grammar model to reduce the chance of nonsense phrases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "-----\n",
    "TODO: Why is there zero probability for sentence with neverbeforseen word?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Underflow error https://en.wikipedia.org/wiki/Arithmetic_underflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_prob_smoothed(counts: dict, word: str)-> float:\n",
    "    \"\"\"Calculate a probability distribution based on evidence from a Counter.\n",
    "    With laplace smoothing!\n",
    "    \"\"\"\n",
    "    N = sum(counts.values())\n",
    "    return (counts[word]+1) / (N + len(counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert round(word_prob_smoothed(counts, \"the\"), 4)  == 0.0291\n",
    "assert round(word_prob_smoothed(counts, \"king\"), 4) == 0.0032"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word                  probability\n",
      "------------------------------\n",
      "there                 0.0023\n",
      "are                   0.0041\n",
      "common                0.00016\n",
      "and                   0.028\n",
      "neverseen             1.1e-06\n",
      "words                 0.00044\n"
     ]
    }
   ],
   "source": [
    "print(f'{\"word\":20}  {\"probability\"}')\n",
    "print('-'*30)\n",
    "for word in words('there are common and neverseen words'):\n",
    "    print(f'{word:20}  {word_prob_smoothed(counts, word):.2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_words_smoothed_in_phrase(phrase):\n",
    "    \"Probability of words, assuming each word is independent of others.\"\n",
    "    return product([word_prob_smoothed(counts, word) for word in words(phrase)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word                            probability\n",
      "--------------------------------------------------\n",
      "the                             0.0290542\n",
      "the the                         0.000844145\n",
      "the the the                     2.45259e-05\n",
      "the sonnets by                  8.58927e-10\n",
      "this is a neverbeforeseen word  6.36721e-16\n"
     ]
    }
   ],
   "source": [
    "print(f'{\"word\":30}  {\"probability\"}')\n",
    "print('-'*50)\n",
    "for phrase in phrases:\n",
    "    print(f'{phrase:30}  {prob_words_smoothed_in_phrase(phrase):.6}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<br>\n",
    "<br> \n",
    "<br>\n",
    "\n",
    "----"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
