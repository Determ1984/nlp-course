Segmenting, Tokenizing, & Stemming
----

__Required__:

- Complete `workbook` in folder
- [Word Tokenization](https://www.youtube.com/watch?v=FFvlT_0pcl8)
- [Word Normalization and Stemming](https://www.youtube.com/watch?v=207x-6KvXK8)
- [Sentence Segmentation](https://www.youtube.com/watch?v=ChXrMzbdeP4)
- Read: [Read Part I & II](http://textminingonline.com/dive-into-nltk-part-ii-sentence-tokenize-and-word-tokenize)

__Optional__:

+ [Webinar on Tokenizing Words and Sentences with NLTK](https://pythonprogramming.net/tokenizing-words-sentences-nltk-tutorial/)

__Challenge__:

- [Fast Word Segmentation of Noisy Text](https://towardsdatascience.com/fast-word-segmentation-for-noisy-text-2c2c41f9e8da)