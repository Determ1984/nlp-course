{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Part-of-Speech (POS) Tagging\n",
    "----\n",
    "<center><img src=\"https://s-media-cache-ak0.pinimg.com/564x/f0/be/22/f0be221344466e36e24c20b581b8d3d3.jpg\" width=\"500\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Is POS: classification, clustering or regression?\n",
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "POS is classification.\n",
    "\n",
    "POS is just hard, mutli-class classification of tokens.\n",
    "\n",
    "Given a token and a context, what is the most-likely, single tag from a group of tags."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "By The End Of This Session You Should Be Able To:\n",
    "----\n",
    "\n",
    "- Explain how Part-of-Speech (POS) Tagging is hard classification\n",
    "- List multiple ways of doing POS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "POS requires building a parse tree based on grammar\n",
    "------\n",
    "\n",
    "<center><img src=\"http://www.nltk.org/book_1ed/tree_images/ch07-tree-1.png\" width=\"1000\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Tagging Hierarchy\n",
    "----\n",
    "\n",
    "<center><img src=\"http://www.nltk.org/book_1ed/tree_images/ch07-tree-1.png\" width=\"1000\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "POS Training Methods\n",
    "---\n",
    "\n",
    "1. Rule-based, aka make a dictionary\n",
    "2. Statistical Models, aka using Graphical Models\n",
    "3. Deep Learning, aka what everyone does now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Rule-based method: Brill’s tagger \n",
    "-----\n",
    "\n",
    "> \"error-driven transformation-based tagger\"\n",
    "\n",
    "A form of supervised learning, which aims to minimize error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Rule-based method: Brill’s tagger \n",
    "-----\n",
    "\n",
    "Integrated guesser (through “lexical rules”)\n",
    "\n",
    "The algorithm starts with initialization, which is the assignment of tags based on their probability for each word (for example, \"dog\" is more often a noun than a verb). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Then \"patches\" are determined via __rules__ that correct (probable) tagging errors made in the initialization phase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "What is the biggest limitation of rule-based methods?\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Language is too complex for these to work well in most cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Challenge Question\n",
    "------\n",
    "\n",
    "When should we use a rule-based model for POS?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "1. Establish baseline\n",
    "2. Specific domains - emojis\n",
    "\n",
    "<center><img src=\"http://thumbpress.com/wp-content/uploads/2013/10/funny-emoticon-story-Miley-Cyrus1.jpg\" width=\"700\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " Statistical Models\n",
    "----\n",
    "\n",
    "Typically the classifier looks at each word in a sentence and decides whether part of speech it is. By combining these predictions, you can use a classifier to identify a sequence of words that make up a tag.\n",
    "\n",
    "- \"Good enough\" for performance and speed\n",
    "- Currently most common but rapidally lossing to Deep Learning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Statistical Model Examples\n",
    "-----\n",
    "\n",
    "- Hidden Markov model (HMM)\n",
    "- Conditional random fields (CRFs)\n",
    "- Viterbi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Hidden Markov model (HMM) \n",
    "----\n",
    "\n",
    "<center><img src=\"images/HMM.JPG\" width=\"700\"/></center>\n",
    "\n",
    "Model a sequence of observed items generated from hidden/latent states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><img src=\"http://i.stack.imgur.com/6pdIT.png\" width=\"700\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Graphic Models\n",
    "---\n",
    "\n",
    "<center><img src=\"images/graph_models.png\" width=\"700\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Discriminative vs Generative Machine Learning Algorithms\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Generative Machine Learning Algorithms\n",
    "-----\n",
    "\n",
    "Try to learn p(x,y) which can be transformed into p(y|x) later to classify the data. \n",
    "\n",
    "Example: Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Discriminative \n",
    "-------\n",
    "\n",
    "Try to learn p(y|x) directly from the data and then try to classify data. \n",
    "\n",
    "Example: Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Deep Learning via Sequence Models\n",
    "-----\n",
    "\n",
    "> Deep Learning is eating machine learning\n",
    "\n",
    "Neural network that takes previous states are inputs to next state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Recurrent neural network (RNN)\n",
    "----\n",
    "\n",
    "![](images/rnn_over_time.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Grammar as foreign language\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "English in | French Out\n",
    "------\n",
    "\n",
    "<center><img src=\"http://pytorch.org/tutorials/_images/seq2seq.png\" width=\"700\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "English in | Grammar Out\n",
    "------\n",
    "\n",
    "<center><img src=\"images/grammar.png\" width=\"700\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "[Source](https://arxiv.org/abs/1412.7449)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Summary\n",
    "-----\n",
    "\n",
    "- Part-of-Speech (POS) tagging is important to NLP because it adding much need metadata to text\n",
    "- Assigns each word to predefined category. Those categories tend to be very general, grammar categories\n",
    "- It is a hard problem that is best tackled with Deep Learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<br>\n",
    "<br> \n",
    "<br>\n",
    "\n",
    "----"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
