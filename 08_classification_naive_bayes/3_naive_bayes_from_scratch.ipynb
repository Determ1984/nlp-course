{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply Bayes Rule to mutli-class document classfication <br> (from scratch)\n",
    "-----\n",
    "\n",
    "![](images/bayes_rule.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Always Add  Smoothing to Naive Bayes\n",
    "------\n",
    "\n",
    "![](images/laplace.png)\n",
    "Laplace Smoothing in this case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "Naive Bayes Classification Steps\n",
    "-------\n",
    "\n",
    "1. Get labeled data\n",
    "1. Preprocess\n",
    "1. Apply Mulitnomial Naive Bayes\n",
    "    1. Calculate document class priors\n",
    "    1. Calculate conditional probabilities of each word for each class\n",
    "    1. Calculate the proportional probabilities for each class of new document\n",
    "    1. Pick the winning class\n",
    "1. Evaluate with metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get data & preprocess\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset -fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "\n",
    "try:\n",
    "    from dataclasses import dataclass\n",
    "except ModuleNotFoundError:\n",
    "    subprocess.check_call([sys.executable, '-m', 'pip', 'install', 'dataclasses'])\n",
    "    from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Data:\n",
    "    id_num: int\n",
    "    label: str\n",
    "    tokens: list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = [Data(id_num=42, label='cat', tokens=\"🐯 😺 🐩 😺\".split()),\n",
    "         Data(43, 'dog',  \"🐶 🐶 🐈 🐩 🐈 🐶 🐶\".split()),\n",
    "         Data(44, 'fish', \"🐟 🐠 🐠\".split()),\n",
    "         Data(45, 'cat',  \"🐶 🐈 🐈 🐈\".split()),\n",
    "         Data(46, 'fish', \"🐟 🐬 🐬 🐠 🐠\".split()),\n",
    "         Data(47, 'fish', \"🐡 🐡 🐠 🐶\".split()),\n",
    "         Data(48, 'dog',  \"🐶 🐶 🐈 🐩 🐶 🐶\".split()),\n",
    "        ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate document class priors\n",
    "---- \n",
    "\n",
    "$$P(c) = \\frac{N_c}{N}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cat', 'dog', 'fish'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What labels are we dealing with?\n",
    "labels = {d.label for d in train}\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many documents are dealing with?\n",
    "n_docs = len(train)\n",
    "n_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fish': 0.42857142857142855,\n",
       " 'dog': 0.2857142857142857,\n",
       " 'cat': 0.2857142857142857}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_priors = {label:sum(1 for d in train if d.label == label)/n_docs\n",
    "                 for label in labels}\n",
    "doc_priors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate conditional probabilities of each word for each class\n",
    "-----\n",
    "\n",
    "$$P(w|c) = \\frac{count(w,c)+1}{count(c)+|V|}$$\n",
    "\n",
    "with Laplace smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten = chain.from_iterable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab: {'😺', '🐩', '🐡', '🐟', '🐈', '🐬', '🐶', '🐯', '🐠'}\n",
      "Cardinality of vocab: 9\n"
     ]
    }
   ],
   "source": [
    "# Get all tokens, aka the vocabulary\n",
    "vocab = set(flatten(d.tokens for d in train))\n",
    "print(\"Vocab:\", vocab)\n",
    "\n",
    "# Cardinality of vocabulary\n",
    "v = len(vocab)\n",
    "print(\"Cardinality of vocab:\", v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>()>,\n",
       "            {'fish': defaultdict(float,\n",
       "                         {'😺': 0.047619047619047616,\n",
       "                          '🐩': 0.047619047619047616,\n",
       "                          '🐡': 0.14285714285714285,\n",
       "                          '🐟': 0.14285714285714285,\n",
       "                          '🐈': 0.047619047619047616,\n",
       "                          '🐬': 0.14285714285714285,\n",
       "                          '🐶': 0.09523809523809523,\n",
       "                          '🐯': 0.047619047619047616,\n",
       "                          '🐠': 0.2857142857142857}),\n",
       "             'dog': defaultdict(float,\n",
       "                         {'😺': 0.045454545454545456,\n",
       "                          '🐩': 0.13636363636363635,\n",
       "                          '🐡': 0.045454545454545456,\n",
       "                          '🐟': 0.045454545454545456,\n",
       "                          '🐈': 0.18181818181818182,\n",
       "                          '🐬': 0.045454545454545456,\n",
       "                          '🐶': 0.4090909090909091,\n",
       "                          '🐯': 0.045454545454545456,\n",
       "                          '🐠': 0.045454545454545456}),\n",
       "             'cat': defaultdict(float,\n",
       "                         {'😺': 0.17647058823529413,\n",
       "                          '🐩': 0.11764705882352941,\n",
       "                          '🐡': 0.058823529411764705,\n",
       "                          '🐟': 0.058823529411764705,\n",
       "                          '🐈': 0.23529411764705882,\n",
       "                          '🐬': 0.058823529411764705,\n",
       "                          '🐶': 0.11764705882352941,\n",
       "                          '🐯': 0.11764705882352941,\n",
       "                          '🐠': 0.058823529411764705})})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cond_prob = defaultdict(lambda: defaultdict(float))\n",
    "\n",
    "for label in labels:\n",
    "    # For a given label, get a list of all the tokens for all the docs \n",
    "    label_tokens = list(chain.from_iterable(d.tokens for d in train if d.label == label))\n",
    "    for token in vocab:\n",
    "        # Find conditional probability: token count / total count\n",
    "        cond_prob[label][token] = (label_tokens.count(token)+1) / (len(label_tokens) + v)\n",
    "cond_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test that each label is a pmf\n",
    "for label in labels:\n",
    "    assert round(sum(cond_prob[label].values())) == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a new document without a label,  calculate the proportional probabilities for each class\n",
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ P(c | X) = P(c) •  \\prod_{i=1}^n P(x_i | c)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from functools import reduce\n",
    "\n",
    "def  product(iterable):\n",
    "    return reduce(operator.mul, iterable, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('fish', 0.0)\n",
      "('dog', 0.0)\n",
      "('cat', 0.0)\n"
     ]
    }
   ],
   "source": [
    "# test = Data(id_num=90, label=None, tokens=\"😺\".split())\n",
    "# test = Data(id_num=91, label=None, tokens=\"🐶 🐶\".split()) \n",
    "# test = Data(id_num=92, label=None, tokens=\"🐶 😺\".split())\n",
    "# test = Data(id_num=93, label=None, tokens=\"🐈 🐈 🐶 🐶 🐡 🐬 🐡 🐬 🐡 🐬\".split())\n",
    "# test = Data(id_num=94, label=None, tokens=\"🐬\".split())\n",
    "test = Data(id_num=95, label=None, tokens=\"🐹\".split()) # Out of sample prediction\n",
    "# test = Data(id_num=95, label=None, tokens=\"🐹 🐶\".split()) # Out of sample prediction\n",
    "\n",
    "prob_predicted = defaultdict(float)\n",
    "for label in labels:\n",
    "    prob_predicted[label] = doc_priors[label] * product(cond_prob[label][t] for t in test.tokens)\n",
    "    \n",
    "print(*dict(prob_predicted).items(), sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pick the winning class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fish\n"
     ]
    }
   ],
   "source": [
    "# Naive\n",
    "label, prob = max(prob_predicted.items(),\n",
    "                  key=itemgetter(1))\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fish dog cat\n"
     ]
    }
   ],
   "source": [
    "# Handle ties\n",
    "label, prob = max(prob_predicted.items(),\n",
    "                  key=itemgetter(1))\n",
    "print(*(k for k, v in prob_predicted.items() if v == prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fish\n"
     ]
    }
   ],
   "source": [
    "# Handle ties and fall back to document priors if winning probability is zero\n",
    "label, prob = max(prob_predicted.items(),\n",
    "                  key=itemgetter(1))\n",
    "if prob > 0:\n",
    "    print(*(k for k, v in prob_predicted.items() if v == prob))\n",
    "else:\n",
    "    label, prob = max(doc_priors.items(),\n",
    "                      key=itemgetter(1))\n",
    "    print(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary\n",
    "------\n",
    "\n",
    "- Naive Bayes is simple and powerful algorithm for text classification\n",
    "- Always add smoothing to Naive Bayes\n",
    "- Use the Standard Library to create elegant and performant code\n",
    "- Dataclasses are coming soon; Get ready"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "Resources\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/bayes_slide.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # The data from the slide\n",
    "# train = [Data(id_num=1, label='c', tokens=\"C B C\".split()),\n",
    "#          Data(2, 'c', \"C C S\".split()),\n",
    "#          Data(3, 'c', \"C M\".split()),\n",
    "#          Data(4, 'j', \"T J C\".split()),\n",
    "#         ]\n",
    "\n",
    "# test = Data(5, label=None, tokens=\"C C C T J\".split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Zoo\n",
    "------\n",
    "\n",
    "🐶\n",
    "🐕\n",
    "🐩\n",
    "🐯\n",
    "🐈\n",
    "😺\n",
    "🐟\n",
    "🐠\n",
    "🐡\n",
    "🐬\n",
    "🐹"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
