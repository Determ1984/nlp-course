{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Information Retrieval (IR) Evaluation Metrics\n",
    "----\n",
    "\n",
    "<center><img src=\"http://math.sfsu.edu/beck/images/dilbert.accurate.numbers.gif\" width=\"80%\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "By The End Of This Session You Should Be Able To:\n",
    "----\n",
    "\n",
    "- Evaluate an IR system with the following concepts:  \n",
    "    - Precision and recall\n",
    "    - Precision at k\n",
    "    - Mean average precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Confusion Matrix\n",
    "----\n",
    "\n",
    "<center><img src=\"images/cont.png\" width=\"75%\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"images/p_tp.png\" width=\"75%\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"images/recall_tp.png\" width=\"75%\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"images/items.png\" width=\"45%\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"images/precision.png\" width=\"45%\"/></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"images/p.png\" width=\"75%\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"images/r.png\" width=\"75%\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"http://www.info.univ-angers.fr/~gh/Predipath/confus3.jpg\" width=\"75%\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"images/pvsr.png\" width=\"75%\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Precision & Recall as a Bucket & a Well\n",
    "------\n",
    "\n",
    "<center><img src=\"http://www.motherearthnews.com/homesteading-and-livestock/~/media/Images/MEN/Editorial/Blogs/Homesteading%20and%20Livestock/How%20to%20Use%20a%20Well%20Bucket%20Video/free%20well%20picture.jpg\" width=\"75%\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Check for understanding\n",
    "-----\n",
    "\n",
    "If there are 100 documents in a collection that are relevant to a given query and 60 of these items are retrieved in a given search. \n",
    "\n",
    "What is the recall?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "Recall = (60/100) = .60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In a given search, the system retrieves 80 items, out of which 30 are relevant and 50 are non-relevant. \n",
    "\n",
    "What is the precision?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Precison = (30/80) = .375"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "When a query have thousands (or millions) of relevant documents, recall is often not a meaningful metric.\n",
    "\n",
    "No one interested in reading all of them "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Search Engine Results Page (SERP)\n",
    "-----\n",
    "\n",
    "1st position is most important\n",
    "\n",
    "2nd position is sometimes clicked on\n",
    "\n",
    "3rd position is rarely clicked on\n",
    "\n",
    "4th-end Doesn't matter\n",
    "\n",
    "----\n",
    "\n",
    "Above the fold is all that matters. The fold (aka attention) is getting smaller. For example, compare desktop to mobile to watch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Need \"precision at k\" or p@k\n",
    "----\n",
    "\n",
    "For example:\n",
    "\n",
    "if 1st result is relevant p@k = 1.\n",
    "\n",
    "if 1st results i not relevant p@k = 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "[P@10 or \"Precision at 10\"](https://en.wikipedia.org/wiki/Mean_average_precision#Precision_at_K) corresponds to the number of relevant results on the first search results page which typically has 10 shown results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "What is precision at different k for this SERP?\n",
    "\n",
    "1. N / not relevant document\n",
    "2. N / not relevant document\n",
    "3. N / not relevant document\n",
    "4. R / relevant document\n",
    "5. R / relevant document\n",
    "6. N / not relevant document\n",
    "7. R / relevant document \n",
    "8. R / relevant document \n",
    "9. N / not relevant document\n",
    "10. R / relevant document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Here is our data\n",
    "serp = 'N N N R R N R R N R'.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[False, False, False, True, True, False, True, True, False, True]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert to boolean vector\n",
    "serp_relevant = [relevance == 'R' # R = relevant \n",
    "                 for relevance in serp]\n",
    "\n",
    "serp_relevant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.25,\n",
       " 0.4,\n",
       " 0.3333333333333333,\n",
       " 0.42857142857142855,\n",
       " 0.5,\n",
       " 0.4444444444444444,\n",
       " 0.5]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Caluclate precision at each k\n",
    "precisions = [sum(serp_relevant[:k+1])/(k+1) \n",
    "               for k, relevant in enumerate(serp_relevant)]\n",
    "\n",
    "precisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision @1 - 0.0\n",
      "Precision @2 - 0.0\n",
      "Precision @3 - 0.0\n",
      "Precision @4 - 0.25\n",
      "Precision @5 - 0.4\n",
      "Precision @6 - 0.333\n",
      "Precision @7 - 0.429\n",
      "Precision @8 - 0.5\n",
      "Precision @9 - 0.444\n",
      "Precision @10 - 0.5\n"
     ]
    }
   ],
   "source": [
    "# What are the precisions?\n",
    "for (i,value) in enumerate(precisions):\n",
    "    print(f\"Precision @{i+1} - {value:.3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average precision for this query: 0.29\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(\"Average precision for this query: {:.2f}\".format(np.mean(precisions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Performance across multiple queries\n",
    "-----\n",
    "\n",
    "<center><img src=\"images/map.png\" width=\"75%\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "SERP & CTR: It pays be to a winner\n",
    "----\n",
    "\n",
    "<center><img src=\"images/serp-ctr.svg\" width=\"45%\"/></center>\n",
    "\n",
    "The Internet is \"winner take most\". It is best to be #1 in a niche then lower in a wider area."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Discounted Cumulative Gain (DCG)\n",
    "-----\n",
    "\n",
    "The premise of DCG is that highly relevant documents appearing lower in a search result list should be penalized as the graded relevance value is reduced logarithmically proportional to the position of the result. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><img src=\"images/dcg.png\" width=\"75%\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Discounted Cumulative Gain (DCG)\n",
    "------\n",
    "\n",
    "<center><img src=\"images/example.png\" width=\"65%\"/></center>\n",
    "\n",
    "How log \"sucky\" your SERP is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Summary\n",
    "-----\n",
    "\n",
    "- Precision and recall are the just the start of evaluating a IR system\n",
    "- Evaluate a SERP with:\n",
    "    + Precision \n",
    "    + Recall\n",
    "    + p@k\n",
    "    + MAP\n",
    "    - Discounted Cumulative Gain (DCG) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<br>\n",
    "<br> \n",
    "<br>\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "---\n",
    "Advanced metrics\n",
    "----\n",
    "\n",
    "[Fall-out](https://en.wikipedia.org/wiki/Information_retrieval#Fall-out): The proportion of non-relevant documents that are retrieved, out of all non-relevant documents available. \n",
    "\n",
    "![](images/fallout.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "----\n",
    "[Generality](http://crpit.com/confpapers/CRPITV49Yan.pdf): The proportion of relevant items per query.\n",
    "    \n",
    "Larger the collection, the larger will be the number of non-relevant item in given query. Hence, an increase in the level of recall will cause a decrease in precision.\n",
    "\n",
    "[Source](http://www.cs.usc.edu/assets/002/82932.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<br>\n",
    "<br> \n",
    "<br>\n",
    "\n",
    "----"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
